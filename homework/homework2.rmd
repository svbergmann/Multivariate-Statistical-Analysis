---
title: "Multivariate Statistical Analysis"
subtitle: "Homework 2"
author: Lucas Fellmeth, Helen Kafka, Sven Bergmann
date: 02/15/24
output: pdf_document
---

```{r, echo = F}
library(knitr)
opts_chunk$set(tidy.opts = list(width.cutoff = 80), tidy = TRUE)
```

# Problem 1

## (a)

We have $x\in\mathbb{R}^p$, $\mathbb{E}[x] = \mu$, $\text{Cov}(x) = \Sigma$, $A$ is a $p \times p$ constant matrix and $\text{tr}(A v v^\top) = v^\top A v$.
Because $A$ is a constant $p \times p$ matrix, $A$ is symmetric.
Because of this symmetry, it follows that it has a Cholesky decomposition as $A = C^\top C$.

Let $y = C x$.

Then

\begin{align*}
\mathbb{E}[x^\top A x]
&= \mathbb{E}[x^\top C^\top C x] \\
&= \mathbb{E}[(Cx)^\top C x] \\
&= \mathbb{E}[y^\top y] \\
&= \sum_i \mathbb{E}[y_i^2] \\
&= \sum_i \text{Var}(y_i) + \mathbb{E}[y_i]^2 \\
&= \text{tr}(\Sigma_y) + \mu_y^\top \mu_y
\end{align*}

where $\Sigma_y = \mathbb{E}[(y-\mathbb{E}[y])(y-\mathbb{E}[y])^\top) = C \Sigma C^\top$
and $\mu_y = C_\mu$.

\begin{align*}
\implies \mathbb{E}[x^\top A x]
&= \text{tr}(C \Sigma C^\top) + \mu^\top \underbrace{C^\top C}_{=A} \mu \\
&= \text{tr}(\Sigma C^\top C) + \mu^\top A \mu \\
&= \text{tr}(\Sigma A) + \mu^\top A \mu
\end{align*}

## (b)

$X_1, \ldots, X_n$ uncorrelated:

$\text{Cov}(X_i, X_j) = 0$ for $i\neq j$ and $\text{Cov}(X_i, X_i) = \text{Var}(X_i) = \sigma^2$

\begin{align*}
\implies \Sigma =
\begin{pmatrix}
\sigma^2    & 0         & 0         & \ldots    & 0         \\
0           & \sigma^2  & 0         & \ldots    & 0         \\
0           & 0         & \ddots    & \ldots    & \vdots    \\
\vdots      & \vdots    & \ldots    & \ddots    & \vdots    \\
0           & 0         & \ldots    & \ldots    & \sigma^2
\end{pmatrix}
\end{align*}

\begin{align*}
J =
\begin{pmatrix}
1       & \ldots & 1        \\
\vdots  & \ddots & \vdots   \\
1       & \ldots & 1
\end{pmatrix}
\in \mathbb{R}^{p\times p}.
\end{align*}

\begin{align*}
A = T - \frac{1}{p} J =
\begin{pmatrix}
1 - \frac{1}{p} & - \frac{1}{p}     & - \frac{1}{p} & \ldots & - \frac{1}{p}    \\
-\frac{1}{p}    & 1 - \frac{1}{p}   & - \frac{1}{p} & \ldots & - \frac{1}{p}    \\
-\frac{1}{p}    & - \frac{1}{p}     & \ddots        & \ldots & \vdots           \\
\vdots          & \vdots            & \ldots        & \ddots & \vdots           \\
-\frac{1}{p}    & - \frac{1}{p}     & \ldots        & \ldots & 1 - \frac{1}{p}
\end{pmatrix}
\in \mathbb{R}^{p\times p}.
\end{align*}

\begin{align*}
A\Sigma =
\begin{pmatrix}
(1 - \frac{1}{p}) \sigma^2  & - \frac{\sigma^2}{p}          & - \frac{\sigma^2}{p}  & \ldots & - \frac{\sigma^2}{p}     \\
-\frac{\sigma^2}{p}         & (1 - \frac{1}{p}) \sigma^2    & - \frac{1}{p}         & \ldots & - \frac{1}{p}            \\
-\frac{\sigma^2}{p}         & - \frac{\sigma^2}{p}          & \ddots                & \ldots & \vdots                   \\
\vdots                      & \vdots                        & \ldots                & \ddots & \vdots                   \\
-\frac{\sigma^2}{p}         & - \frac{\sigma^2}{p}          & \ldots                & \ldots & (1 - \frac{1}{p}) \sigma^2
\end{pmatrix}
\in \mathbb{R}^{p\times p}.
\end{align*}

\begin{align*}
\mathbb{E}[x^\top A x]
&\overset{a)}{=} \text{tr}(A\Sigma) + \mu^\top A \mu \\
&= \sum_{i=1}^p (1-\frac{1}{p}) \sigma^2 + (\mu \ldots \mu)^\top
\begin{pmatrix}
1 - \frac{1}{p} & - \frac{1}{p}     & - \frac{1}{p} & \ldots & - \frac{1}{p}    \\
-\frac{1}{p}    & 1 - \frac{1}{p}   & - \frac{1}{p} & \ldots & - \frac{1}{p}    \\
-\frac{1}{p}    & - \frac{1}{p}     & \ddots        & \ldots & \vdots           \\
\vdots          & \vdots            & \ldots        & \ddots & \vdots           \\
-\frac{1}{p}    & - \frac{1}{p}     & \ldots        & \ldots & 1 - \frac{1}{p}
\end{pmatrix}
\begin{pmatrix}
\mu \\
\vdots \\
\mu
\end{pmatrix} \\
&= p \cdot (1-\frac{1}{p}) \cdot \sigma^2 + (\underbrace{\mu \cdot (1-\frac{1}{p}) + (p-1) \cdot (-\frac{1}{p}) \cdot \mu}_{\underbrace{= \frac{p-1}{p} \cdot \mu + \frac{1-p}{p} \cdot \mu}_{=0}} \ldots \mu \cdot (1-\frac{1}{p}) + (p-1) \cdot (-\frac{1}{p}) \cdot \mu)
\begin{pmatrix}
\mu \\
\vdots \\
\mu
\end{pmatrix} \\
&= (p-1) \cdot \sigma^2 + (0 \ldots 0) \cdot
\begin{pmatrix}
\mu \\
\vdots \\
\mu
\end{pmatrix} \\
&= (p-1) \cdot \sigma^2
\end{align*}

## (c)

# Problem 2
## (a)
## (b)
```{r}
Sigma <- matrix(data = c(1, -2, 0, -2, 5, 0, 0, 0, 2), nrow = 3, ncol = 3)
print(Sigma)
```
```{r, warning = F, message = F}
library(expm)
```
```{r}
Sigma_sqrt <- sqrtm(Sigma)
print(Sigma_sqrt)
```

# Problem 3
